---
title: DGCNN(ACM Trans on Graphics '19) Review
categories:
- Papers
tags:
- Point Cloud
- ACM
toc: true
toc_sticky: true
toc_label: On this Page
last_modified_at: 2021-09-29T13:42:15+08:00
---

벌써 3번째 포스트지만 아직까지도 Markdown문법이 익숙해지지 않는 것 같다... 기존에는 개인 노션에 논문들을 정리했었는데 업로드 해야할 논문 정리글이 아직도 한참 쌓여 있다. 부지런히 해야지 마음먹긴 했는데 다 업로드 하려면 생각보다 시간은 좀 걸릴 것 같다. 오늘의 포스트 주제는 DGCNN이다. DGCNN은 Dynamic Graph CNN for Learning on Point Clouds에서 제안한 모델로 기존의 모델들과는 다르게 포인트들의 aggregation을 위한 Neighbor를 x,y,z space가 아닌 feature space에서 진행한다는 특이점이 있다. 자세한 내용은 뒤에 쓰기로 하고, 내가 작년 처음 이 논문을 봤을때는 google scholar 인용수가 300 언저리였는데 벌써 1500회를 넘어간다. 인용수만 봐도 배부를듯... 아무튼 Point cloud analysis를 할 경우 빠지지 않고 table에 들어가는 논문인건 확실한 것 같다.

# Intro
___
DGCNN이 가장 크게 지적하는 문제는 다음과 같다.   
- DGCNN 이전의 Point cloud를 Processing하던 network들은 각각의 Point들을 독립적으로 고려하였다  
-> 즉, Point들간의 상관관계를 전혀 파악하지 못하고있다.  
- 처음에 주어진 extrinsic space만을 고려하여 local neighborhood 정보를 획득한다  
-> global shape property를 획득해야 한다.  


위의 각 문제들을 해결하기 위해 DGCNN은 다음과 같은 방법을 채용했다.  
1. x,y,z space가 아닌 매 layer에서의 feature space에서 KNN을 진행하여 새로운 local graph를 생성한다 -> Low level에서는 Local한 정보를 보지만, High Level에서는 Global 정보를 교환 가능  
2. local graph에서의 EdgeConv를 도입하여 local geometric structure를 파악한다. -> Point들간의 상관관계를 고려하여 feature를 embedding한다.  

# Main
___
**EdgeConv**  

![fig1](/assets/images/posts/DGCNN-fig1.PNG){: .open-new width="100%" height="100%"}  
DGCNNN 저자들은 PointNet과 Convolution으로 부터 영감을 받았다고 한다. 사실 PointNet++과 같이 각 layer에서 hierarchical한 구조를 위해 Neighbor를 grouping되어있는 상태는 해당 Neighbor들과 연결되어 있는 graph 관점으로도 생각할수가 있다. 따라서 data가 graph라면 각 node들간의 상관관계를 고려해야하기에 본 논문은 EdgeConv를 적용하였다고 한다.  
이제 위 그림을 가지고 Edge Conv를 이해해보자 우선 EdgeConv의 formulation은 다음과 같다.  
$ x^\prime_i = \square_{j:(i,j) \in \varepsilon} h_\Theta(x_i,x_j) $  
이 수식은 위의 그림의 맨 왼쪽에 해당한다. 의미를 해석해 보자면 각 point $x_i$와 해당 포인트의 neighbor point $x_j$가 있을때 둘을 특정 Edge function $h_\Theta$ 거쳐 edge feature를 생성하고 이를 symmetric function $\square$를 통해 aggregation 한다고 이해할 수 있다.  
그렇다면 edge feature $h_\Theta$는 어떻게 만들어질까? 논문에서 시도한 방법은 총 5가지지만 결과적으로 논문에서 채택한 수식만은 다음과 같다.  
$h_\Theta(x_i, x_j) = \bar{h}_\Theta(x_i, x_j - x_i)$.  

해당 edge function이 의미하는 바는 자기 자신의 절대좌표 $x_i$와 자신으로부터 neighbor의 상대좌표 $x_j-x_i$ 를 모두 고려하겠다는 것을 의미한다. 이를 통해 확실히 MLP만 태우던 PointNet에 비해 확실하게 Point들의 관계를 파악할 수 있게 되었다. 위식을 좀더 풀어써 보자면 다음과 같다.
$e^\prime_{ijm} = \text{ReLU}(\theta_m \cdot (x_j - x_i) + \phi_m +x_i), \\ x^\prime_i = \max_{j:(i,j)\in \varepsilon} e^\prime_{ij}$

$e$는 neighbor와의 상대적인 좌표로 update한 edge이며 해당 edge를 max pooling을 통해 update한다고 생각하면 되겠다.

**Dynamic graph**  

본 논문의 핵심 아이디어지만 실제 분량도 되게 적고 내용도 되게 간단하다. 저자들은 graph가 x,y,z space에서 KNN을 통해 생성된 형태로 끝까지 지속되는 것이 아니라 매 layer마다 지속적으로 dynamic하게 변경되게끔 설계하였다. 기대하는 바는 초기 layer에서는 Local한 정보를 파악해서 high level 에서는 구조가 유사하거나 같은 semantic을 가진 Point들이 연결되는 것이다. 실제로 다음 그림을 보면 의도한 바가 어느정도는 달성된 것 같다. 
![fig2](/assets/images/posts/DGCNN-fig2.PNG){: .open-new width="100%" height="100%"}  

**Results**  

![fig3](/assets/images/posts/DGCNN-fig3.PNG){: .open-new width="100%" height="100%"} 
DGCNN이 처음 나왔던 당시 기준으로 기존의 모델들보다 상대적으로 높은 성능을 달성하는데 성공했다. 이외에도 Complexity와 KNN에 관한 analysis도 있으니 관심있는 사람들은 한번씩 찾아보면 좋을것 같다. 간단히 몇가지만 짚어보자면 매 layer마다 KNN과 EdgeConv 해야하지만 maxpooling만을 사용하는 기존의 PointNet++대비 성능은 올랐으며 메모리는 거의 동일함에도 불구하고 속도가 거의 10배정도 빠르다고한다. 근데 코드를 몇번 직접 돌려본 입장에서 보면 DGCNN은 Best validation accuracy를 기준으로 모델을 선택하고, PointNet++은 Last epoch을 선택해서 발생하는 문제일수도 있을것 같다.  
![fig4](/assets/images/posts/DGCNN-fig4.PNG){: .open-new width="100%" height="100%"} 
하나만 더 보자면 위의 Part segmentation 성능인데 논문 주장대로라면 비행기 날개는 날개끼리, 의자라면 다리는 다리끼리 KNN이 될테니 Part segmentation 성능이 가장 잘 나와야 말이 될것 같은데, 정작 성능은 classification보다도 성능차이를 보이지 못했다. 그래서 저널으로 낸건가...? 아무튼 논문의 주장이 조금 약해진것처럼 보인다.

# 마치며
___
DGCNN 논문은 아직까지도 활발하게 사용되고 있는 Point cloud 분석용 모델로 Point cloud의 선두주자 PointNet, PointNet++을 제외하고 현재 가장 많은 citation을 받은 모델이 아닐까 싶다. 복잡한 모델이 아니라서 핵심위주로 설명했으니, 세세한 detail은 직접 논문을 찾아보길 바란다. 이상!  

**References**

[https://arxiv.org/abs/1801.07829.pdf](https://arxiv.org/abs/1801.07829.pdf)
